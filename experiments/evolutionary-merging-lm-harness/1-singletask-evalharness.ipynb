{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/leonardo/home/userexternal/tmencatt/miniconda3/envs/mergenetic/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pymoo.algorithms.soo.nonconvex.ga import GA\n",
    "from pymoo.operators.crossover.sbx import SBX\n",
    "from pymoo.operators.mutation.pm import PM\n",
    "from pymoo.operators.repair.rounding import RoundingRepair\n",
    "from pymoo.operators.sampling.rnd import IntegerRandomSampling\n",
    "\n",
    "from mergenetic import PROJECT_ROOT\n",
    "from mergenetic.evaluation import *\n",
    "from mergenetic.utils import *\n",
    "from mergenetic.merging.merger import *\n",
    "from mergenetic.optimization import *\n",
    "from mergenetic.merging import SlerpMerger, TiesDareMerger\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from mergenetic.optimization import MergingProblem\n",
    "from mergenetic.searcher import SearcherLMEval\n",
    "from dataclasses import dataclass\n",
    "import yaml\n",
    "import pickle\n",
    "from end2end_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Evolutionary Model Merging with Mergenetic\n",
    "\n",
    "In this notebook, we illustrate how to perform evolutionary merging of language models using the Mergenetic library for a **problem defined via lm-eval harness**. \n",
    "\n",
    "The notebook covers the following steps:\n",
    "\n",
    "1. **Configuration Merging** - Define the configuration for the merging problem.\n",
    "1. **Data Loading** – Read the CSV dataset.\n",
    "2. **Anchor Extraction** – Randomly select anchor points.\n",
    "3. **Pre-Evaluation (Optional)** – Evaluate the base models (can be skipped).\n",
    "4. **Theta Retrieval** – Obtain the latent ability parameters.\n",
    "5. **Train/Test Split** – Separate the sampled anchors from the rest of the data.\n",
    "6. **Set Performance Estimation Parameters** – Unpack and configure the parameters for performance estimation.\n",
    "7. **Define the Merger** – Create the merging object (using SlerpMerger in this example).\n",
    "8. **Define the Optimization Problem** – Specify the problem instance that wraps the merger, evaluation data, and settings.\n",
    "9. **Define the Evolutionary Algorithm** – Set up a genetic algorithm (GA) with sampling, crossover, and mutation operators.\n",
    "10. **Run the Search** – Execute the evolutionary search and test the merged model.\n",
    "\n",
    "If you wish to run the same problem via a script, the code can be found at [this script](end2end.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Configuration for Merging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This configuration file sets up the parameters for running the cross-lingual evolutionary merging process. The goal is to merge language models using evolutionary algorithms while controlling evaluation and performance estimation aspects. To do so we need to furnish a list of details, like the model that must be merged, the task on which they should be evaluated,... Most importantly, three types of parameters must be furnished:\n",
    "\n",
    "REQUIRED PARAMETERS:\n",
    "\n",
    "- **pop_size** (`int`):  \n",
    "  Specifies the size of the population in the evolutionary search (e.g., `25`).\n",
    "\n",
    "- **n_iter** (`int`):  \n",
    "  The number of iterations (or generations) to run the evolutionary algorithm (e.g., `7`).\n",
    "\n",
    "- **ft_model_paths** (`List[str]`):  \n",
    "  A list of fine-tuning model identifiers/paths. In this example, it includes:  \n",
    "  - `\"OpenLLM-Ro/RoMistral-7b-Instruct\"`  \n",
    "  - `\"meta-math/MetaMath-Mistral-7B\"`\n",
    "\n",
    "- **path_to_store_merged_model** (`str`):  \n",
    "  Path where the merged model(s) will be stored during the evolutionary search (e.g., `\"experiments/models/merged/\"`).\n",
    "\n",
    "- **path_to_store_yaml** (`str`):  \n",
    "  Directory path for saving YAML configuration files (e.g., `\"experiments/evolutionary-merging-lm-harness/romanian_math/\"`).\n",
    "\n",
    "- **dtype** (`str`):  \n",
    "  Data type used for model parameters; here it is `\"float16\"`.\n",
    "\n",
    "- **run_id** (`str`):  \n",
    "  A unique identifier for this run or experiment (e.g., `\"romanian_math_gmpirt\"`).\n",
    "\n",
    "- **bench** (`str`):  \n",
    "  Specifies the benchmark to use for evaluation (e.g., `\"gsm8k\"`). \n",
    "\n",
    "- **mode** (`str`):  \n",
    "  Indicates the merging mode (e.g., `\"gmpirt\"`).\n",
    "\n",
    "- **seed** (`int`):  \n",
    "  Random seed value to ensure reproducibility (e.g., `420`). &#128521;\n",
    "\n",
    "- **dataset_path** (`str`):  \n",
    "  File path to the dataset used for evaluation (e.g., `\"data/new_datasets/gsm8k/gsm8k_test_romanian.csv\"`).\n",
    "\n",
    "- **tasks** (`dict[str, str]`):  \n",
    "  The lm-eval harness task on which we wish to test the model:\n",
    "  - `sample`: `\"gsm8k-ro\"`  \n",
    "  - `test`: `\"gsm8k-ro\"`\n",
    "\n",
    "- **metric** (`str`):  \n",
    "  The evaluation metric to be used (e.g., `\"exact_match\"`) is the key of the dictionary that must be used to access the quantitive performance of the model in the task defined above from the dictionary returned by lm-eval harness.  \n",
    "  *Default is `\"acc\"` if not explicitly set.*\n",
    "\n",
    "\n",
    "OPTIONAL GENERIC PARAMETERS:\n",
    "\n",
    "- **device** (`str | None`):  \n",
    "  Specifies the computing device (e.g., `\"cuda:0\"` for GPU, or `None` for CPU).\n",
    "\n",
    "OPTIONAL EVALUATION PARAMETERS:\n",
    "\n",
    "- **ft_model_to_evaluate** (`List[str]`):  \n",
    "  List of fine-tuned models to be evaluated in order to compute the latent ability ot this endpoint models. These are the models that we are going to merge. Model should be passed here when we do not have already the correctness score to extract the thetas. In alternative, you could pass directly the correctness path in responses_path.\n",
    "\n",
    "- **eval_task** (`str`):  \n",
    "  Specifies the evaluation task for computing the correctness scores of the model that we will evaluate (e.g., `\"MATH\"`).\n",
    "\n",
    "- **output_path_evaluation** (`List[str]`):  \n",
    "  List of paths where evaluation outputs will be saved.\n",
    "\n",
    "- **eval_batch_size** (`int`):  \n",
    "  Batch size used during evaluation (e.g., `64`).\n",
    "\n",
    "OPTIONAL THETA ESTIMATION PARAMETERS:\n",
    "\n",
    "- **responses_path** (`List[str]`):  \n",
    "  List of paths to model responses. \n",
    "\n",
    "- **output_path_theta_estimation** (`List[str]`):  \n",
    "  List of paths to save theta estimation results. Example values include:  \n",
    "  - `\"experiments/evolutionary-merging-lm-harness/results/ft_ro_theta.pkl\"`  \n",
    "  - `\"experiments/evolutionary-merging-lm-harness/results/metamath_ro_theta.pkl\"`\n",
    "\n",
    "\n",
    "OPTIONAL FOR PROMPTING\n",
    "- **custom_prompt_template** (`str`):  \n",
    "  A custom prompt template that can be used in prompting the language model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating the configuration\n",
    "config = ConfigCrossLingualLMEval(\n",
    "    pop_size=25,\n",
    "    n_iter=7,\n",
    "    ft_model_paths=[\n",
    "        \"/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/models/base/OpenLLM-Ro/RoMistral-7b-Instruct\",\n",
    "        \"/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/models/base/meta-math/MetaMath-Mistral-7B\",\n",
    "    ],\n",
    "    path_to_store_merged_model=\"/leonardo_scratch/large/userexternal/tmencatt\",\n",
    "    path_to_store_yaml=\"/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/experiments/evolutionary-merging-lm-harness/romanian_math/\",\n",
    "    dtype=\"float16\",\n",
    "    run_id=\"romanian_math_gmpirt\",\n",
    "    bench=\"gsm8k\",\n",
    "    mode=\"gmpirt\",\n",
    "    seed=420,\n",
    "    tasks={\"sample\": \"gsm8k-ro\", \"test\": \"gsm8k-ro\"},\n",
    "    metric=\"exact_match\",\n",
    "    dataset_path=\"/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/data/new_datasets/gsm8k/gsm8k_test_romanian.csv\",\n",
    "    device=\"cuda:0\",\n",
    "    ft_model_to_evaluate=[\"\", \"\"],\n",
    "    eval_task=\"MATH\",\n",
    "    output_path_evaluation=[\"\", \"\"],\n",
    "    eval_batch_size=64,\n",
    "    responses_path=[\"\", \"\"],\n",
    "    output_path_theta_estimation=[\n",
    "        \"/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/experiments/evolutionary-merging-lm-harness/romanian_math/results/ft_ro_theta.pkl\",\n",
    "        \"/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/experiments/evolutionary-merging-lm-harness/romanian_math/results/metamath_ro_theta.pkl\",\n",
    "    ],\n",
    "    thetas_paths=[\n",
    "        \"/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/experiments/evolutionary-merging-lm-harness/romanian_math/results/ft_ro_theta.pkl\",\n",
    "        \"/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/experiments/evolutionary-merging-lm-harness/romanian_math/results/metamath_ro_theta.pkl\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Optional "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Evaluation configuration:  ConfigCrossLingualLMEval(pop_size=25, n_iter=7, ft_model_paths=['/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/models/base/OpenLLM-Ro/RoMistral-7b-Instruct', '/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/models/base/meta-math/MetaMath-Mistral-7B'], path_to_store_merged_model='/leonardo_scratch/large/userexternal/tmencatt', path_to_store_yaml='/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/experiments/evolutionary-merging-lm-harness/romanian_math/', dtype='float16', run_id='romanian_math_gmpirt', dataset_path='/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/data/new_datasets/gsm8k/gsm8k_test_romanian.csv', thetas_paths=['/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/experiments/evolutionary-merging-lm-harness/romanian_math/results/ft_ro_theta.pkl', '/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/experiments/evolutionary-merging-lm-harness/romanian_math/results/metamath_ro_theta.pkl'], bench='gsm8k', mode='gmpirt', seed=420, tasks={'sample': 'gsm8k-ro', 'test': 'gsm8k-ro'}, metric='exact_match', device='cuda:0', ft_model_to_evaluate=['', ''], eval_task='MATH', output_path_evaluation=['', ''], eval_batch_size=64, responses_path=['', ''], output_path_theta_estimation=['/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/experiments/evolutionary-merging-lm-harness/romanian_math/results/ft_ro_theta.pkl', '/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/experiments/evolutionary-merging-lm-harness/romanian_math/results/metamath_ro_theta.pkl'], custom_prompt_template='')\n",
      "STEP 2 completed: Predictions obtained\n"
     ]
    }
   ],
   "source": [
    "# STEP 3. Get the responses of the base models\n",
    "predictions = evaluate_model(config)\n",
    "print(\"STEP 2 completed: Predictions obtained\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 3 completed: Thetas obtained\n"
     ]
    }
   ],
   "source": [
    "# STEP 4. Get the thetas\n",
    "thetas = retrieve_thetas(config)\n",
    "print(\"STEP 3 completed: Thetas obtained\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 4 completed: Accuracy estimation parameters set\n"
     ]
    }
   ],
   "source": [
    "# STEP 5. Unpack some parameters and set the accuracy estimation parameters\n",
    "pop_size = config.pop_size\n",
    "n_iter = config.n_iter\n",
    "run_id = config.run_id\n",
    "bench = config.bench\n",
    "mode = config.mode\n",
    "tasks = config.tasks\n",
    "metric = config.metric\n",
    "est_parameters = AccuracyEstimationLMEval(\n",
    "    thetas=thetas, bench=bench, mode=mode, tasks=tasks, metric=metric\n",
    ")\n",
    "print(\"STEP 4 completed: Accuracy estimation parameters set\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 5 completed: Merger defined\n"
     ]
    }
   ],
   "source": [
    "# STEP 7. Define the merger\n",
    "\n",
    "merger = SlerpMerger(\n",
    "    run_id=run_id,\n",
    "    path_to_base_model=config.ft_model_paths[0],\n",
    "    path_to_model_1=config.ft_model_paths[1],\n",
    "    path_to_store_yaml=config.path_to_store_yaml,\n",
    "    path_to_store_merged_model=config.path_to_store_merged_model,\n",
    "    dtype=config.dtype,\n",
    "    layer_range_base_model=[0, 32],\n",
    "    layer_range_model_1=[0, 32],\n",
    ")\n",
    "\n",
    "\n",
    "if config.device:\n",
    "    device = config.device\n",
    "else:\n",
    "    device = \"cuda\"\n",
    "print(\"STEP 5 completed: Merger defined\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 8 completed: Problem defined\n"
     ]
    }
   ],
   "source": [
    "# STEP 8. Define the problem\n",
    "problem = AnchoredCrossLingualMathProblemLMEval(\n",
    "    merger,\n",
    "    evolve_task=tasks[\"sample\"],\n",
    "    test_task=tasks[\"test\"],\n",
    "    n_var=11,\n",
    "    n_obj=1,\n",
    "    n_eq_constr=0,\n",
    "    n_ieq_constr=0,\n",
    "    discrete=True,\n",
    "    eval_batch_size=64,\n",
    "    device=device,\n",
    ")\n",
    "problem.set_est_parameters(est_parameters)\n",
    "print(\"STEP 8 completed: Problem defined\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STEP 9 completed: Algorithm defined\n"
     ]
    }
   ],
   "source": [
    "# STEP 9. Define the algorithm\n",
    "algorithm = GA(\n",
    "    pop_size=pop_size,\n",
    "    sampling=IntegerRandomSampling(),\n",
    "    crossover=SBX(),\n",
    "    mutation=PM(),\n",
    "    eliminate_duplicates=True,\n",
    ")\n",
    "print(\"STEP 9 completed: Algorithm defined\", flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yaml configuration file created at /leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/experiments/evolutionary-merging-lm-harness/romanian_math/romanian_math_gmpirt/config.yaml\n",
      "Deleted folder and all contents: /leonardo_scratch/large/userexternal/tmencatt/romanian_math_gmpirt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warmup loader cache: 100%|██████████| 2/2 [00:00<00:00, 68.57it/s]\n",
      "Executing graph:   0%|          | 0/1457 [00:00<?, ?it/s]WARNING:root:Using common submatrix of size torch.Size([32000, 4096]) for lm_head.weight\n",
      "Executing graph:   0%|          | 5/1457 [00:06<29:29,  1.22s/it]WARNING:root:Using common submatrix of size torch.Size([32000, 4096]) for model.embed_tokens.weight\n",
      "Executing graph:   4%|▍         | 64/1457 [00:14<05:06,  4.55it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m result_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiments/evolutionary-merging-lm-harness\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      3\u001b[0m searcher \u001b[38;5;241m=\u001b[39m SearcherLMEval(problem, algorithm, result_path, n_iter, run_id \u001b[38;5;241m=\u001b[39m run_id, seed\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mseed, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m \u001b[43msearcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/src/mergenetic/searcher/searcher.py:146\u001b[0m, in \u001b[0;36mSearcherLMEval.search\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msearch\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame:\n\u001b[1;32m    145\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Executes the search algorithm and saves the results to a CSV file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 146\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mminimize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malgorithm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mn_iter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSearch Completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult_X \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mX\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproblem\u001b[38;5;241m.\u001b[39mdiscrete \u001b[38;5;28;01melse\u001b[39;00m result\u001b[38;5;241m.\u001b[39mX\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/pymoo/optimize.py:67\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(problem, algorithm, termination, copy_algorithm, copy_termination, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m     algorithm\u001b[38;5;241m.\u001b[39msetup(problem, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# actually execute the algorithm\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m \u001b[38;5;66;03m# store the deep copied algorithm in the result object\u001b[39;00m\n\u001b[1;32m     70\u001b[0m res\u001b[38;5;241m.\u001b[39malgorithm \u001b[38;5;241m=\u001b[39m algorithm\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/pymoo/core/algorithm.py:138\u001b[0m, in \u001b[0;36mAlgorithm.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_next():\n\u001b[0;32m--> 138\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresult()\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/pymoo/core/algorithm.py:158\u001b[0m, in \u001b[0;36mAlgorithm.next\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# call the advance with them after evaluation\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m infills \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minfills\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malgorithm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(infills\u001b[38;5;241m=\u001b[39minfills)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;66;03m# if the algorithm does not follow the infill-advance scheme just call advance\u001b[39;00m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/pymoo/core/evaluator.py:69\u001b[0m, in \u001b[0;36mEvaluator.eval\u001b[0;34m(self, problem, pop, skip_already_evaluated, evaluate_values_of, count_evals, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;66;03m# evaluate the solutions (if there are any)\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(I) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     67\u001b[0m \n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# do the actual evaluation - call the sub-function to set the corresponding values to the population\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproblem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpop\u001b[49m\u001b[43m[\u001b[49m\u001b[43mI\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluate_values_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# update the function evaluation counter\u001b[39;00m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m count_evals:\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/pymoo/core/evaluator.py:90\u001b[0m, in \u001b[0;36mEvaluator._eval\u001b[0;34m(self, problem, pop, evaluate_values_of, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m X \u001b[38;5;241m=\u001b[39m pop\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;66;03m# call the problem to evaluate the solutions\u001b[39;00m\n\u001b[0;32m---> 90\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_values_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevaluate_values_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_as_dictionary\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;66;03m# for each of the attributes set it to the problem\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, val \u001b[38;5;129;01min\u001b[39;00m out\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/pymoo/core/problem.py:257\u001b[0m, in \u001b[0;36mProblem.evaluate\u001b[0;34m(self, X, return_values_of, return_as_dictionary, *args, **kwargs)\u001b[0m\n\u001b[1;32m    254\u001b[0m     only_single_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(X, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(X, np\u001b[38;5;241m.\u001b[39mndarray))\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# this is where the actual evaluation takes place\u001b[39;00m\n\u001b[0;32m--> 257\u001b[0m _out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_values_of\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    259\u001b[0m out \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    260\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m _out\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    261\u001b[0m \n\u001b[1;32m    262\u001b[0m     \u001b[38;5;66;03m# copy it to a numpy array (it might be one of jax at this point)\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/pymoo/core/problem.py:297\u001b[0m, in \u001b[0;36mProblem.do\u001b[0;34m(self, X, return_values_of, *args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;66;03m# do the function evaluation\u001b[39;00m\n\u001b[1;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melementwise:\n\u001b[0;32m--> 297\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate_elementwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_evaluate_vectorized(X, out, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/pymoo/core/problem.py:315\u001b[0m, in \u001b[0;36mProblem._evaluate_elementwise\u001b[0;34m(self, X, out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39melementwise_func(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n\u001b[1;32m    314\u001b[0m \u001b[38;5;66;03m# execute the runner\u001b[39;00m\n\u001b[0;32m--> 315\u001b[0m elems \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melementwise_runner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[38;5;66;03m# for each evaluation call\u001b[39;00m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m elems:\n\u001b[1;32m    319\u001b[0m \n\u001b[1;32m    320\u001b[0m     \u001b[38;5;66;03m# for each key stored for this evaluation\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/pymoo/core/problem.py:32\u001b[0m, in \u001b[0;36mLoopedElementwiseEvaluation.__call__\u001b[0;34m(self, f, X)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, f, X):\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m X]\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/pymoo/core/problem.py:25\u001b[0m, in \u001b[0;36mElementwiseEvaluationFunction.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m     24\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m()\n\u001b[0;32m---> 25\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproblem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/src/mergenetic/optimization/merging_problem.py:637\u001b[0m, in \u001b[0;36mMergingLMEValProblem._evaluate\u001b[0;34m(self, x, out, *args, **kwargs)\u001b[0m\n\u001b[1;32m    634\u001b[0m clean_gpu()\n\u001b[1;32m    636\u001b[0m \u001b[38;5;66;03m# Convert the genotype to a path to the model configuration file\u001b[39;00m\n\u001b[0;32m--> 637\u001b[0m path_to_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_array_to_genotype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;66;03m# Load model and tokenizer on the appropriate device\u001b[39;00m\n\u001b[1;32m    640\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_from_genotype_to_phenotype(path_to_model)\n",
      "File \u001b[0;32m/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/src/mergenetic/optimization/merging_problem.py:523\u001b[0m, in \u001b[0;36mMergingLMEValProblem._from_array_to_genotype\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    520\u001b[0m path_to_config \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmerger\u001b[38;5;241m.\u001b[39mcreate_individual_configuration(x)\n\u001b[1;32m    522\u001b[0m \u001b[38;5;66;03m# merge the models using phenotype \u001b[39;00m\n\u001b[0;32m--> 523\u001b[0m path_to_model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerger\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge_model_from_configuration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path_to_model\n",
      "File \u001b[0;32m/leonardo_work/IscrC_MGNTC/tmencatt/mergenetic/src/mergenetic/merging/merger.py:160\u001b[0m, in \u001b[0;36mMerger.merge_model_from_configuration\u001b[0;34m(self, path_to_yaml, cuda, copy_tokenizer, lazy_unpickle, low_cpu_memory)\u001b[0m\n\u001b[1;32m    152\u001b[0m options_merging \u001b[38;5;241m=\u001b[39m MergeOptions(\n\u001b[1;32m    153\u001b[0m     cuda\u001b[38;5;241m=\u001b[39mcuda,\n\u001b[1;32m    154\u001b[0m     copy_tokenizer\u001b[38;5;241m=\u001b[39mcopy_tokenizer,\n\u001b[1;32m    155\u001b[0m     lazy_unpickle\u001b[38;5;241m=\u001b[39mlazy_unpickle,\n\u001b[1;32m    156\u001b[0m     low_cpu_memory\u001b[38;5;241m=\u001b[39mlow_cpu_memory,\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    159\u001b[0m \u001b[38;5;66;03m# merge the models\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m \u001b[43mrun_merge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmerge_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43mout_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath_to_store_merged_model\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions_merging\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;66;03m# safe clean to avoid out of memory\u001b[39;00m\n\u001b[1;32m    167\u001b[0m clean_gpu()\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/mergekit/merge.py:96\u001b[0m, in \u001b[0;36mrun_merge\u001b[0;34m(merge_config, out_path, options, config_source)\u001b[0m\n\u001b[1;32m     89\u001b[0m exec \u001b[38;5;241m=\u001b[39m Executor(\n\u001b[1;32m     90\u001b[0m     tasks\u001b[38;5;241m=\u001b[39mtargets,\n\u001b[1;32m     91\u001b[0m     math_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mcuda \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     92\u001b[0m     storage_device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m options\u001b[38;5;241m.\u001b[39mlow_cpu_memory \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     93\u001b[0m )\n\u001b[1;32m     95\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 96\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquiet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquiet\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTokenizerInfo\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/mergekit/graph.py:197\u001b[0m, in \u001b[0;36mExecutor.run\u001b[0;34m(self, quiet)\u001b[0m\n\u001b[1;32m    194\u001b[0m     arguments[name] \u001b[38;5;241m=\u001b[39m value\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m value\n\u001b[0;32m--> 197\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43marguments\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m arguments\n\u001b[1;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(res, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;129;01mand\u001b[39;00m res\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_device:\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/mergekit/merge_methods/slerp.py:60\u001b[0m, in \u001b[0;36mSlerpTask.execute\u001b[0;34m(self, tensors)\u001b[0m\n\u001b[1;32m     55\u001b[0m prepped_tensors \u001b[38;5;241m=\u001b[39m [a[\u001b[38;5;241m1\u001b[39m], b[\u001b[38;5;241m1\u001b[39m]]\n\u001b[1;32m     57\u001b[0m rectify_embed_sizes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight_info, prepped_tensors)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m---> 60\u001b[0m     \u001b[43mslerp\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprepped_tensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprepped_tensors\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;241m.\u001b[39mto(prepped_tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdtype)\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;241m.\u001b[39mto(prepped_tensors[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     67\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/mergekit/merge_methods/slerp.py:134\u001b[0m, in \u001b[0;36mslerp\u001b[0;34m(t, v0, v1, DOT_THRESHOLD, eps)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m# Normalize the vectors to get the directions and angles\u001b[39;00m\n\u001b[1;32m    133\u001b[0m v0 \u001b[38;5;241m=\u001b[39m normalize(v0, eps)\n\u001b[0;32m--> 134\u001b[0m v1 \u001b[38;5;241m=\u001b[39m \u001b[43mnormalize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Dot product with the normalized vectors (can't use np.dot in W)\u001b[39;00m\n\u001b[1;32m    137\u001b[0m dot \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(v0 \u001b[38;5;241m*\u001b[39m v1)\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/mergekit/merge_methods/slerp.py:167\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(v, eps)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mnormalize\u001b[39m(v: np\u001b[38;5;241m.\u001b[39mndarray, eps: \u001b[38;5;28mfloat\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m     norm_v \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m norm_v \u001b[38;5;241m>\u001b[39m eps:\n\u001b[1;32m    169\u001b[0m         v \u001b[38;5;241m=\u001b[39m v \u001b[38;5;241m/\u001b[39m norm_v\n",
      "File \u001b[0;32m~/miniconda3/envs/mergenetic/lib/python3.12/site-packages/numpy/linalg/_linalg.py:2736\u001b[0m, in \u001b[0;36mnorm\u001b[0;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[1;32m   2734\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m x_real\u001b[38;5;241m.\u001b[39mdot(x_real) \u001b[38;5;241m+\u001b[39m x_imag\u001b[38;5;241m.\u001b[39mdot(x_imag)\n\u001b[1;32m   2735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2736\u001b[0m     sqnorm \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2737\u001b[0m ret \u001b[38;5;241m=\u001b[39m sqrt(sqnorm)\n\u001b[1;32m   2738\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# STEP 10. Define the searcher and run it\n",
    "result_path = \"experiments/evolutionary-merging-lm-harness\"\n",
    "searcher = SearcherLMEval(\n",
    "    problem,\n",
    "    algorithm,\n",
    "    result_path,\n",
    "    n_iter,\n",
    "    run_id=run_id,\n",
    "    seed=config.seed,\n",
    "    verbose=False,\n",
    ")\n",
    "searcher.search()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "searcher.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mergenetic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
